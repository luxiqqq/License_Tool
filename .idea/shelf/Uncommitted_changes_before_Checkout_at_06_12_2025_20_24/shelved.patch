Index: app/services/scancode_service.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\"\"\"\r\nThis module handles the interaction with the ScanCode Toolkit CLI for raw license detection\r\nand implements a post-processing layer using an LLM to filter false positives.\r\n\"\"\"\r\n\r\nimport os\r\nimport json\r\nimport subprocess\r\nimport re\r\nfrom re import match\r\nfrom typing import List, Dict, Any, Optional, Tuple\r\nfrom app.core.config import SCANCODE_BIN, OUTPUT_BASE_DIR, MINIMAL_JSON_BASE_DIR\r\nfrom app.services.llm_helper import _call_ollama_gpt\r\n\r\n\r\n#  ------------ MAIN FUNCTION TO EXECUTE SCANCODE -----------------\r\n\r\ndef run_scancode(repo_path: str) -> dict:\r\n    \"\"\"\r\n    Executes ScanCode on the target repository and parses the JSON output.\r\n\r\n    Note: Real-time progress is printed to the standard output.\r\n\r\n    Args:\r\n        repo_path (str): The file system path to the target repository.\r\n\r\n    Returns:\r\n        dict: The parsed JSON data from ScanCode, with the top-level\r\n              'license_detections' key removed to reduce payload size.\r\n    \"\"\"\r\n\r\n    # 1. Definizione degli ignore pattern\r\n    ignore_path = os.path.join(os.path.dirname(__file__), 'license_rules.json')\r\n    with open(ignore_path, 'r', encoding='utf-8') as f:\r\n        rules = json.load(f)\r\n    ignore_patterns = rules.get(\"ignored_patterns\", [])\r\n\r\n    # Assicuriamoci che la directory di output esista\r\n    os.makedirs(OUTPUT_BASE_DIR, exist_ok=True)\r\n\r\n    repo_name = os.path.basename(os.path.normpath(repo_path))\r\n    output_file = os.path.join(OUTPUT_BASE_DIR, f\"{repo_name}_scancode_output.json\")\r\n\r\n    # 2. Costruzione del comando base\r\n    cmd = [\r\n        SCANCODE_BIN,\r\n        # Opzioni Licenza\r\n        \"--license\",\r\n        \"--license-text\",\r\n        \"--filter-clues\",\r\n        \"--license-clarity-score\",\r\n\r\n        # Opzioni Statistiche e Classificazione\r\n        \"--tallies\",\r\n        \"--tallies-key-files\",\r\n        \"--classify\",\r\n    ]\r\n\r\n    # 3. Aggiunta dinamica degli ignore pattern\r\n    for pattern in ignore_patterns:\r\n        cmd.extend([\"--ignore\", pattern])\r\n\r\n    # 4. Aggiunta output e target\r\n    cmd.extend([\r\n        \"--json-pp\", output_file,\r\n        repo_path,\r\n    ])\r\n\r\n    print(f\"\uD83D\uDE80 Avvio ScanCode su: {repo_name}\")\r\n    print(f\"\uD83D\uDCC2 Output su: {output_file}\")\r\n\r\n    # Real-time output (NO capture_output)\r\n    process = subprocess.Popen(cmd)\r\n\r\n    # Wait for completion and get return code\r\n    returncode = process.wait()\r\n\r\n    # Error handling according to ScanCode rules\r\n    if returncode > 1:\r\n        raise RuntimeError(f\"Errore ScanCode (exit {returncode})\")\r\n\r\n    if returncode == 1:\r\n        print(\"⚠ ScanCode ha completato con errori non fatali (exit 1).\")\r\n\r\n    if not os.path.exists(output_file):\r\n        raise RuntimeError(\"ScanCode non ha generato il file JSON\")\r\n\r\n    # 1. Load the generated JSON\r\n    with open(output_file, \"r\", encoding=\"utf-8\") as f:\r\n        scancode_data = json.load(f)\r\n\r\n    # ⬇ Rimuovi la chiave \"license_detections\" dal JSON di primo livello\r\n    # (Nota: license_detections a volte è pesante e ridondante se usi i dettagli dei file)\r\n    scancode_data.pop(\"license_detections\", None)\r\n\r\n    # 2. Overwrite the file with modified data\r\n    with open(output_file, \"w\", encoding=\"utf-8\") as f:\r\n        json.dump(scancode_data, f, indent=4, ensure_ascii=False)\r\n\r\n    print(\"✅ ScanCode completato e JSON processato.\")\r\n\r\n    # 3. Ritorna i dati modificati\r\n    return scancode_data\r\n\r\n\r\n#  ------------ FUNCTIONS TO FILTER RESULTS WITH LLM -----------------\r\n\r\ndef remove_main_license(main_spdx, path, scancode_data) -> dict:\r\n    \"\"\"\r\n    Removes the main license from the ScanCode results for a specific file path.\r\n    This prevents the LLM from being biased by the main license when filtering.\r\n    \"\"\"\r\n    for file_entry in scancode_data.get(\"files\", []):\r\n        for det in file_entry.get(\"matches\", []):\r\n            if file_entry.get(\"path\") == path and det.get(\"license_spdx\") == main_spdx:\r\n                scancode_data[\"files\"].remove(file_entry)\r\n\r\n    return scancode_data\r\n\r\n\r\ndef filter_with_llm(scancode_data: dict, main_spdx: str, path: str) -> dict:\r\n    \"\"\"\r\n    Filters ScanCode results using an LLM to remove false positives.\r\n\r\n    It constructs a minimal JSON representation of the file matches and asks the LLM\r\n    to validate the 'matched_text' against known license patterns.\r\n    \"\"\"\r\n    minimal = build_minimal_json(scancode_data)\r\n    # print(json.dumps(minimal, indent=4))\r\n    scan_clean = remove_main_license(main_spdx, path, minimal)\r\n\r\n    if main_spdx != \"UNKNOWN\":\r\n        regex_filtered = filter_license_data(scan_clean, detected_main_spdx=True)\r\n    else:\r\n        regex_filtered = filter_license_data(scan_clean, detected_main_spdx=False)\r\n\r\n    post_regex_cleaning = remove_mainspdx_from_filespdx(regex_filtered, main_spdx)\r\n    return post_regex_cleaning\r\n\r\n\r\ndef build_minimal_json(scancode_data: dict) -> dict:\r\n    \"\"\"\r\n    Builds a minimal JSON structure from the ScanCode data.\r\n    Instead of using the global 'license_detections' list (which requires the LLM to group),\r\n    we iterate directly over files and collect their matches.\r\n    \"\"\"\r\n    minimal = {\"files\": []}\r\n\r\n    # Iterate over files (which have already been filtered by remove_main_license)\r\n    for file_entry in scancode_data.get(\"files\", []):\r\n        path = file_entry.get(\"path\")\r\n        legal = file_entry.get(\"is_legal\")\r\n        key_file = file_entry.get(\"is_key_file\")\r\n        if not path:\r\n            continue\r\n\r\n        file_matches = []\r\n\r\n        # ScanCode file-level detections\r\n        for det in file_entry.get(\"license_detections\", []):\r\n\r\n            # 'matches' contains details (start_line, end_line, matched_text)\r\n            for match in det.get(\"matches\", []):\r\n\r\n                if match.get(\"from_file\") == path:\r\n                    file_matches.append({\r\n                        \"license_spdx\": match.get(\"license_expression_spdx\"),\r\n                        \"matched_text\": match.get(\"matched_text\"),\r\n                    })\r\n\r\n        score = file_entry.get(\"percentage_of_license_text\")\r\n\r\n        if file_matches:\r\n            minimal[\"files\"].append({\r\n                \"path\": path,\r\n                \"is_legal\": legal,\r\n                \"is_key_file\": key_file,\r\n                \"matches\": file_matches,\r\n                \"score\": score\r\n            })\r\n\r\n\r\n    # Assicura che la cartella esista e scrive il JSON minimale invece di leggerlo\r\n    os.makedirs(MINIMAL_JSON_BASE_DIR, exist_ok=True)\r\n    output_minimal = os.path.join(MINIMAL_JSON_BASE_DIR, \"minimal_output.json\")\r\n\r\n    with open(output_minimal, \"w\", encoding=\"utf-8\") as f:\r\n        json.dump(minimal, f, indent=4, ensure_ascii=False)\r\n\r\n    return minimal\r\n\r\n\r\ndef ask_llm_to_filter_licenses(minimal_json: dict) -> dict:\r\n    \"\"\"\r\n    Sends the reduced JSON to the LLM and returns the clean JSON (matches filtered).\r\n    Analyzes ONLY matched_text.\r\n    \"\"\"\r\n\r\n    prompt = f\"\"\"\r\nSei un esperto di licenze open source.\r\n\r\nTi fornisco un JSON contenente una lista di FILE, ognuno con i suoi MATCH di licenza rilevati.\r\nIl tuo compito è analizzare ogni match e decidere se è valido o meno.\r\n\r\nANALIZZA SOLO:\r\n    matched_text  (per capire se è una licenza)\r\n    license_spdx  (per validità del nome della licenza)\r\n\r\nGli altri campi (path, score) sono metadati.\r\n\r\n────────────────────────────────────────\r\nCRITERIO DI FILTRO (usa matched_text + license_spdx)\r\n────────────────────────────────────────\r\n\r\nSCARTA il match se matched_text è:\r\n\r\n❌ un riferimento (es. \"see LICENSE\", \"Apache License link\")\r\n❌ un link a licenze (https://opensource.org/licenses/…)\r\n❌ una descrizione della licenza (non il testo reale)\r\n❌ un frammento di documentazione / commento generico\r\n❌ una citazione in changelog, tutorial, README, docstring\r\n❌ un semplice nome della licenza senza header/testo\r\n❌ un match ereditato da altri file (IGNORA from_file)\r\n❌ testo troppo breve o non legal-formal (meno di ~20 caratteri)\r\n\r\nTIENI il match SOLO se matched_text è:\r\n\r\n✅ un testo reale di licenza (MIT, GPL, Apache, BSD, MPL, etc.)\r\n✅ un header di licenza usato nei file sorgente\r\n✅ un testo formale di licenza >= 20 caratteri\r\n✓ uno SPDX tag valido (es. “SPDX-License-Identifier: Apache-2.0”)\r\n\r\n────────────────────────────────────────\r\nVALIDAZIONE DI license_spdx (nuova regola)\r\n────────────────────────────────────────\r\n\r\n1. Se `license_spdx` è il nome di una licenza *valida* (SPDX ufficiale):\r\n   → tienilo così com'è.\r\n\r\n2. Se `license_spdx` NON è valido:\r\n   → analizza *solo* il `matched_text` e prova a riconoscere una licenza reale.\r\n      - se il testo contiene una licenza riconoscibile\r\n        (es. inizia con “Apache License Version 2.0”, “MIT License”, “GNU General Public License”, ecc.)\r\n        → SOSTITUISCI license_spdx con l’identificatore SPDX corretto.\r\n      - se dal testo NON si riesce a identificare alcuna licenza valida\r\n        → SCARTA completamente il match.\r\n\r\n────────────────────────────────────────\r\nFORMATO RISPOSTA **OBBLIGATORIO**\r\n────────────────────────────────────────\r\n\r\nRispondi SOLO con un JSON:\r\n\r\n{{\r\n  \"files\": [\r\n    {{\r\n      \"path\": \"<path>\",\r\n      \"matches\": [\r\n        {{\r\n          \"license_spdx\": \"<SPDX>\"\r\n        }}\r\n      ]\r\n      \"score\": <score>\r\n    }}\r\n  ]\r\n}}\r\n\r\n- includi solo i file che hanno almeno un match valido\r\n- per ogni match tieni il license_spdx (eventualmente corretto)\r\n- non inserire nulla che non rispetta i criteri sopra\r\n\r\n────────────────────────────────────────\r\n\r\nEcco il JSON da analizzare:\r\n\r\n{json.dumps(minimal_json, indent=2)}\r\n\"\"\"\r\n\r\n    llm_response = _call_ollama_gpt(prompt)\r\n\r\n    try:\r\n        return json.loads(llm_response)\r\n    except json.JSONDecodeError:\r\n        raise RuntimeError(\"Invalid response from model.\")\r\n\r\n\r\n#  ------------ FUNCTIONS TO DETECT MAIN LICENSE FROM SCANCODE JSON -----------------\r\ndef filter_license_data(data: dict, detected_main_spdx: bool) -> dict:\r\n    \"\"\"\r\n    Filtra i risultati di Scancode usando regole caricate da un file JSON esterno.\r\n    \"\"\"\r\n\r\n    # --- 1. CARICAMENTO E COMPILAZIONE REGOLE ---\r\n\r\n    rules_path = os.path.join(os.path.dirname(__file__), 'license_rules.json')\r\n\r\n    if not os.path.exists(rules_path):\r\n        raise FileNotFoundError(f\"Impossibile trovare il file di regole: {rules_path}\")\r\n\r\n    with open(rules_path, 'r', encoding='utf-8') as f:\r\n        rules = json.load(f)\r\n\r\n    # Compiliamo le liste di esclusione in un'unica regex ottimizzata con OR logic (|)\r\n    # Questo è molto più veloce di fare un loop su ogni stringa.\r\n    re_references = re.compile(\"|\".join(rules.get(\"ignore_patterns\", [])), re.IGNORECASE)\r\n    re_docs_changelog = re.compile(\"|\".join(rules.get(\"changelog_patterns\", [])), re.IGNORECASE)\r\n\r\n    # Compiliamo la regex per il tag SPDX\r\n    re_spdx_tag = re.compile(rules.get(\"spdx_tag_pattern\", \"\"), re.IGNORECASE)\r\n\r\n    # Compiliamo i pattern per riconoscere TESTO LEGALE EFFETTIVO delle licenze\r\n    valid_license_patterns = []\r\n    for pattern in rules.get(\"valid_license_text_patterns\", []):\r\n        try:\r\n            valid_license_patterns.append(re.compile(pattern, re.IGNORECASE))\r\n        except re.error:\r\n            pass  # Skip pattern non validi\r\n\r\n    # Compiliamo i pattern per riconoscere LINK VALIDI a licenze (RST, Markdown, URL)\r\n    valid_link_patterns = []\r\n    for pattern in rules.get(\"valid_license_link_patterns\", []):\r\n        try:\r\n            valid_link_patterns.append(re.compile(pattern, re.IGNORECASE))\r\n        except re.error:\r\n            pass  # Skip pattern non validi\r\n\r\n    # Lunghezza minima del testo\r\n    min_text_length = rules.get(\"min_matched_text_length\", 20)\r\n\r\n    filtered_files = {\"files\": []}\r\n\r\n    # --- 2. ELABORAZIONE ---\r\n\r\n    files = data.get('files', [])\r\n\r\n    for file_obj in files:\r\n        file_path = file_obj.get('path')\r\n        matches = file_obj.get('matches', [])\r\n        file_score = file_obj.get('score', 0)\r\n        legal = file_obj.get('is_legal')\r\n        key_file = file_obj.get('is_key_file')\r\n\r\n        if legal is True:\r\n            filtered_files[\"files\"].append({\r\n                \"path\": file_path,\r\n                \"matches\": file_obj.get('matches', []),\r\n                \"score\": file_score\r\n            })\r\n            continue\r\n        elif legal is False and detected_main_spdx is True and key_file is True:\r\n            continue\r\n\r\n        valid_matches = []\r\n\r\n        for match in matches:\r\n            matched_text = match.get('matched_text', '').strip()\r\n            spdx = match.get('license_spdx', '')\r\n\r\n            # --- FASE A: FILTRO PRELIMINARE SUL TESTO ---\r\n\r\n            # 0. Check se è un LINK VALIDO a una licenza (RST, Markdown, URL diretto)\r\n            # Questi link sono utili e NON devono essere scartati\r\n            is_valid_license_link = False\r\n            for pattern_re in valid_link_patterns:\r\n                if pattern_re.search(matched_text):\r\n                    is_valid_license_link = True\r\n                    break\r\n\r\n            # 1. Lunghezza minima (salvo se contiene SPDX tag esplicito o è un link valido)\r\n            if len(matched_text) < min_text_length and \"SPDX-License-Identifier\" not in matched_text and not is_valid_license_link:\r\n                continue\r\n\r\n            # 2. Scarta Riferimenti/Link generici (\"see LICENSE\", \"http://...\")\r\n            # MA NON scartare se è un link valido a licenza riconosciuto\r\n            # Applichiamo questo filtro solo se il testo è breve (< 300 char).\r\n            if len(matched_text) < 300 and not is_valid_license_link:\r\n                if re_references.search(matched_text):\r\n                    continue\r\n\r\n            # 3. Scarta Linguaggio da Changelog/Docs (deprecate, switch to...)\r\n            # MA NON scartare se è un link valido a licenza\r\n            if not is_valid_license_link:\r\n                if re_docs_changelog.search(matched_text):\r\n                    continue\r\n\r\n            # --- FASE B: VALIDAZIONE E CORREZIONE SPDX ---\r\n\r\n            final_spdx = None\r\n            is_valid_spdx = True\r\n\r\n            # Verifica validità base dello scancode trovato\r\n            if not spdx or \"unknown\" in spdx.lower() or \"scancode\" in spdx.lower():\r\n                is_valid_spdx = False\r\n\r\n            # --- FASE C: VERIFICA CHE IL TESTO SIA LEGALE EFFETTIVO ---\r\n\r\n            # Check se il testo contiene frasi legali tipiche di licenze\r\n            has_valid_legal_text = False\r\n\r\n            # I link validi a licenze sono considerati testo legale valido\r\n            if is_valid_license_link:\r\n                has_valid_legal_text = True\r\n\r\n            # Check pattern di testo legale\r\n            if not has_valid_legal_text:\r\n                for pattern_re in valid_license_patterns:\r\n                    if pattern_re.search(matched_text):\r\n                        has_valid_legal_text = True\r\n                        break\r\n\r\n            # Check per tag SPDX esplicito nel testo\r\n            spdx_tag_match = re_spdx_tag.search(matched_text)\r\n            if spdx_tag_match:\r\n                has_valid_legal_text = True\r\n                # Se troviamo un tag SPDX esplicito, usiamo quello come SPDX finale\r\n                if not is_valid_spdx:\r\n                    final_spdx = spdx_tag_match.group(1)\r\n\r\n            # Se non è testo legale valido e non c'è tag SPDX, scarta\r\n            if not has_valid_legal_text and not is_valid_spdx:\r\n                continue\r\n\r\n            # Determina SPDX finale\r\n            if is_valid_spdx:\r\n                final_spdx = spdx\r\n            elif not final_spdx and has_valid_legal_text:\r\n                # Testo legale valido ma nessun SPDX trovato - lo teniamo con SPDX originale o unknown\r\n                final_spdx = spdx if spdx else \"LicenseRef-scancode-unknown\"\r\n\r\n            # Se abbiamo trovato un SPDX valido (originale o recuperato) lo aggiungiamo\r\n            if final_spdx:\r\n                valid_matches.append({\r\n                    \"license_spdx\": final_spdx,\r\n                    \"matched_text\": matched_text\r\n                })\r\n\r\n        # Salvataggio se ci sono match validi e score sufficiente\r\n        if valid_matches:\r\n            filtered_files[\"files\"].append({\r\n                \"path\": file_path,\r\n                \"matches\": valid_matches,\r\n                \"score\": file_score\r\n            })\r\n\r\n    # --- 3. OUTPUT FILE ---\r\n    # Definisci MINIMAL_JSON_BASE_DIR nel tuo codice globale o passalo come argomento se serve\r\n    # Qui assumo esista nel contesto o uso una default locale\r\n    base_dir = globals().get('MINIMAL_JSON_BASE_DIR', './output')\r\n    os.makedirs(base_dir, exist_ok=True)\r\n    output_minimal = os.path.join(base_dir, \"filtered_output.json\")\r\n\r\n    with open(output_minimal, \"w\", encoding=\"utf-8\") as f:\r\n        json.dump(filtered_files, f, indent=4, ensure_ascii=False)\r\n\r\n    return filtered_files\r\n\r\ndef remove_mainspdx_from_filespdx(data: dict, main_spdx: str) -> dict:\r\n    # Nota il [:] alla fine: stiamo iterando su una COPIA della lista\r\n    for file_entry in data.get(\"files\", [])[:]:\r\n\r\n        matches = file_entry.get(\"matches\", [])\r\n        should_remove = True\r\n\r\n        for m in matches:\r\n            if m.get(\"license_spdx\") != main_spdx:\r\n                should_remove = False\r\n                break  # Trovato un motivo per rimuovere, smettiamo di cercare nei match\r\n\r\n        if should_remove:\r\n            data[\"files\"].remove(file_entry) # Rimuoviamo il file una volta sola\r\n\r\n    return data\r\n\r\n#  ------------ FUNZIONI PER RILEVARE LA LICENZA PRINCIPALE DAL JSON SCANCODE -----------------\r\n\r\ndef _is_valid(value: Optional[str]) -> bool:\r\n    \"\"\"Verifies if a string is a valid SPDX and not None/empty/UNKNOWN.\"\"\"\r\n    return bool(value) and value != \"UNKNOWN\"\r\n\r\n\r\ndef _extract_first_valid_spdx(entry: Dict[str, Any]) -> Optional[Tuple[str, str]]:\r\n    \"\"\"\r\n    Returns the first valid SPDX found in the ScanCode entry,\r\n    searching in the detected expression, license_detections, and finally in licenses.\r\n\r\n    Returns: (spdx_expression, path) or None.\r\n    \"\"\"\r\n    if not isinstance(entry, dict):\r\n        return None\r\n\r\n    path = entry.get(\"path\") or \"\"\r\n\r\n    # 1. Check main detected license expression\r\n    spdx = entry.get(\"detected_license_expression_spdx\")\r\n    if _is_valid(spdx):\r\n        return spdx, path\r\n\r\n    # 2. Check individual detections\r\n    # Although the root output 'license_detections' may be removed,\r\n    # this key is still present inside each 'files' object.\r\n    for detection in entry.get(\"license_detections\", []) or []:\r\n        det_spdx = detection.get(\"license_expression_spdx\")\r\n        if _is_valid(det_spdx):\r\n            return det_spdx, path\r\n\r\n    # 3. Check SPDX keys in detailed licenses\r\n    for lic in entry.get(\"licenses\", []) or []:\r\n        spdx_key = lic.get(\"spdx_license_key\")\r\n        if _is_valid(spdx_key):\r\n            return spdx_key, path\r\n\r\n    return None\r\n\r\n\r\ndef _pick_best_spdx(entries: List[Dict[str, Any]]) -> Optional[Tuple[str, str]]:\r\n    \"\"\"\r\n    Sorts files closest to root (lower path depth) and\r\n    returns the first valid SPDX license found.\r\n\r\n    Returns: (spdx_expression, path) or None.\r\n    \"\"\"\r\n    if not entries:\r\n        return None\r\n\r\n    # Sort: use path depth (count of \"/\") as key\r\n    # Lower count means closer to root.\r\n    sorted_entries = sorted(entries, key=lambda e: (e.get(\"path\", \"\") or \"\").count(\"/\"))\r\n\r\n    for entry in sorted_entries:\r\n        res = _extract_first_valid_spdx(entry)\r\n        if res:\r\n            # res is already a tuple (spdx, path)\r\n            return res\r\n\r\n    return None\r\n\r\n\r\ndef detect_main_license_scancode(data: dict) -> Optional[Tuple[str, str]] | str:\r\n    \"\"\"\r\n    Identifies the main license of the project based on ScanCode results.\r\n\r\n    Strategy:\r\n    1. Search in most likely license candidates (e.g., LICENSE/license files).\r\n    2. Use COPYING as fallback.\r\n    3. Use other relevant paths as last resort.\r\n\r\n    Returns: (spdx_expression, path) or \"UNKNOWN\" (simplified return type for this special case).\r\n    \"\"\"\r\n\r\n    license_candidates = []\r\n    copying_candidates = []\r\n    other_candidates = []\r\n\r\n    for entry in data.get(\"files\", []):\r\n        path = entry.get(\"path\") or \"\"\r\n        if not path:\r\n            continue\r\n\r\n        lower = path.lower()\r\n        basename = os.path.basename(lower)\r\n\r\n        # Ignore NOTICE/COPYRIGHT\r\n        if basename.startswith(\"notice\") or basename.startswith(\"copyright\"):\r\n            continue\r\n\r\n        # Classification of candidates\r\n        if basename.startswith(\"license\"):\r\n            license_candidates.append(entry)\r\n        elif basename.startswith(\"copying\"):\r\n            copying_candidates.append(entry)\r\n        # If not already a primary candidate and contains 'license' or 'copying'\r\n        elif \"license\" in lower or \"copying\" in lower:\r\n            other_candidates.append(entry)\r\n\r\n    # 1. Try first choice: LICENSE file\r\n    result = _pick_best_spdx(license_candidates)\r\n    if result:\r\n        return result\r\n\r\n    # 2. Try fallback: COPYING file\r\n    result = _pick_best_spdx(copying_candidates)\r\n    if result:\r\n        return result\r\n\r\n    # 3. Try last resort: other relevant paths\r\n    result = _pick_best_spdx(other_candidates)\r\n    if result:\r\n        return result\r\n\r\n    return \"UNKNOWN\"\r\n\r\n\r\n#  ------------ FUNCTIONS TO EXTRACT RESULTS FROM FILTERED LLM JSON -----------------\r\n\r\ndef extract_file_licenses_from_llm(llm_data: dict) -> Dict[str, str]:\r\n    \"\"\"\r\n    Extracts the license for each file starting from the LLM-filtered JSON.\r\n    llm_data has a different format than the original ScanCode JSON.\r\n    \"\"\"\r\n\r\n    results = {}\r\n\r\n    for f in llm_data.get(\"files\", []):\r\n        path = f.get(\"path\")\r\n        matches = f.get(\"matches\", [])\r\n\r\n        if not matches:\r\n            continue\r\n\r\n        # If there are multiple matches, combine them with AND (like ScanCode tool)\r\n        unique_spdx = list({m.get(\"license_spdx\") for m in matches if m.get(\"license_spdx\")})\r\n\r\n        if not unique_spdx:\r\n            continue\r\n\r\n        if len(unique_spdx) == 1:\r\n            results[path] = unique_spdx[0]\r\n        else:\r\n            results[path] = \" AND \".join(unique_spdx)\r\n\r\n    return results\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/services/scancode_service.py b/app/services/scancode_service.py
--- a/app/services/scancode_service.py
+++ b/app/services/scancode_service.py
@@ -29,11 +29,22 @@
               'license_detections' key removed to reduce payload size.
     """
 
-    # 1. Definizione degli ignore pattern
-    ignore_path = os.path.join(os.path.dirname(__file__), 'license_rules.json')
-    with open(ignore_path, 'r', encoding='utf-8') as f:
-        rules = json.load(f)
-    ignore_patterns = rules.get("ignored_patterns", [])
+    # 1. Definizione degli ignore pattern (legge prima patterns_to_ignore.json)
+    patterns_path = os.path.join(os.path.dirname(__file__), 'patterns_to_ignore.json')
+    rules_path = os.path.join(os.path.dirname(__file__), 'license_rules.json')
+
+    ignore_patterns = []
+    if os.path.exists(patterns_path):
+        with open(patterns_path, 'r', encoding='utf-8') as f:
+            p = json.load(f)
+        ignore_patterns = p.get("ignored_patterns", []) or []
+    elif os.path.exists(rules_path):
+        with open(rules_path, 'r', encoding='utf-8') as f:
+            r = json.load(f)
+        ignore_patterns = r.get("ignored_patterns", []) or []
+
+    # normalizza e rimuove valori falsy
+    ignore_patterns = [str(x) for x in ignore_patterns if x]
 
     # Assicuriamoci che la directory di output esista
     os.makedirs(OUTPUT_BASE_DIR, exist_ok=True)
